# Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector

## 论文内容

### Abstract

​    Conventional methods for object detection typically require a substantial amount of training data and preparing such high-quality training data is very labor-intensive. In this paper, we propose a novel few-shot object detection network that aims at detecting objects of unseen categories with only a few annotated examples. Central to our method are our Attention-RPN, Multi-Relation Detector and Contrastive Training strategy, which exploit the similarity between the few shot support set and query set to detect novel objects while suppressing false detection in the background. To train our network, we contribute a new dataset that contains 1000 categories of various objects with high-quality annotations. To the best of our knowledge, this is one of the first datasets specifically designed for few-shot object detection. Once our few-shot network is trained, it can detect objects of unseen categories without further training or finetuning. Our method is general and has a wide range of potential applications. We produce a new state-of-the-art performance on different datasets in the few-shot setting. The dataset link is https://github.com/fanq15/Few-Shot-Object- Detection-Dataset.

### 摘要

​        传统基于全监督的目标检测方法需要大量的数据集支撑，而准备这样高质量的数据集是非常消耗劳动力的。本文基于Few-Shot提出了新的检测网络，通过少量标注的数据集实现对于未知类别目标的检测。方法的核心之处在于**注意力RPN**、**多重相似度探测器**及**双路对比训练策略**，利用Few-Shot数据集中支持集与查询数据集之间的相似度来检测显著目标的同时抑制背景中错误的检测。为了训练网络，本文提出了包含1000类目标且具有高质量标注的数据集。这也是第一个专门针对Few-Shot检测网络设计的数据集。当我们的网络训练好以后，就可以直接用来预测未知类别目标而不用针对性地训练或者微调。这项研究有很广泛的应用前景，本文在Few-Shot数据集的多个不同数据集中有很好的表现。数据集的链接如下：[数据集](https://github.com/fanq15/Few-Shot-Object-Detection-Dataset)

### 引言

​        现有的目标检测方法需要大量的数据集以及较长的训练时间，这也是研究基于Few-Shot目标检测方法的动力所在。Few-Shot学习是一项针对现实场景中目标具有光照条件、形状、纹理等较大变化的挑战。随着基于Few-Shot的分类方法不断取得新的进展，检测却没有突破，可能因为将Few-Shot分类方法迁移到检测中比较困难。**对于目标检测，本文认为一些新的目标之所以检测不出来可能是因为经过RPN网络后得到的候选框分值较低**，这就导致了Few-Shot分类与Few-Shot检测间的区别。目前的一些Few-Shot检测网络都需要微调才能实现对于新目标的检测。

​        本文中，为了解决上述的Few-Shot检测网络存在的问题，在测试集的所有前景目标中检测出特定目标种类，主要的贡献如下：

- 提出了通用的Few-Shot检测网络，能够在不进行重新训练或者微调的前提下检测未知目标。
- 提供了一个包含1000类别（每个类别只有简单几个样本）的数据集。

### 相关研究

​        **常规目标检测**：常规目标检测很难适用到只包含少量样本的未知类别目标检测场景。

​        **Few-Shot学习**：早期的研究试图学习一般的先验，例如人工设计可以在不同类别样本中共享的特征。一些研究集中在基于人工设计的不同类别目标间的距离度量。最近的研究趋势是设计一个通用的代理或者策略在不同的任务中引导监督学习，通过不断地积累知识，网络就能捕捉到不同任务中的结构变化。这个研究方向一般称为**元学习(meta-learning)**。在这个领域中，有人提出一个由双网络共享权值组成的连体网络，两个网络的输入分别为支持数据和查询数据，并通过logistic回归度量支持数据与查询数据间的距离。这种度量的策略只考虑了支持数据与查询数据间的内在特征差异，忽略了两者的类别差异。随后的工作有用GAN网络来建立不同类别之间的关系模型、使用通用的代理引导参数优化等。到目前为止，很少有Few-Shot的工作取得突破进展，主要进展都在分类任务上，很少有目标检测、实例分割、人体运动预测等。

### FSOD

​        Few-Shot学习的关键在于相关模型在遇到新的类别目标时所展示的泛化能力。因此，一个具有大量目标类别的高多样性数据集对于训练出一个能够检测未知目标的通用模型及进行令人信服的评估是必需的。但是目前的数据集都不满足需求，所以本文创建了一个新的Few-Shot数据集。

#### 数据集组成 

​        本文基于目前现有的监督学习大规模检测数据集建立自己的数据集。这些数据集无法直接使用的原因如下：

- 不同数据集的标注不统一，比如具有相同语义信息的目标在不同数据集中被标记为不同类别。
- 数据集标注中存在漏标、标框不准、重叠框等问题导致较大部分的标注有干扰。
- 训练测试集的划分与Few-Shot要求不统一，需要针对Few-Shot重新划分。

​        为了构建数据集，本文首先总结出来一个标记系统，将具有相同语义的目标标注进行统一，并删去语义信息不属于任何标注类别的目标。然后删除掉标注不好的、标注框尺度太小（小于图像大小0.05%）的样本。再按照Few-Shot的设定对数据集进行训练集和测试集的划分，使得训练集和测试集没有目标类别的重叠。为了方便导入预训练模型，本文将训练集中目标的类别设定为COCO数据集中的种类。然后选择与目前训练集中目标种类差别最大的200个类别作为测试集，防止标签泄露。衡量差别的方法是 is-a 分类法中两个类别语义间最短的路径。剩下的类别则合并到总共包含800个类别目标的训练集中。在本文构建的1000类别数据集中，531个类别来自ImageNet数据集，469个来自Open Image数据集。

#### 数据集分析

​    本文的数据集主要针对Few-Shot任务设计，新数据集包含1000个类别，800/200个类别分别用于训练和测试阶段，约有66000张图和182000个检测框。数据集有如下属性：

- 类别多样化程度高，数据集包含83个父语义，并进一步划分为1000个子类别。训练与测试的类别具有非常不同语义的划分，更迎合Few-Shot的应用需求。
- 数据集挑战性高，数据集中目标框的宽高比、大小有很大的差异，且部分图像目标数较多。在测试集中还包含不属于上述标签系统中的类别，增加了Few-Shot任务的挑战。
- 数据集虽然有大量的类别，但是训练图像和目标框的数量远远小于其他大型基准数据集。

### 方法陈述

#### 问题定位

​        给定一张具有特定目标特写的支持图像S以及一张具有潜在特定类别目标的查询图像Q，那么任务就是在查询图像中找到与S中类别相同的潜在目标对象，并将所有目标用紧密的框标注出来。如果支持数据集中包含N个类别且每个类别有K个样本，那么任务就可以称为N-way K-shot检测。

#### 网络结构

​        本文提出了一个出色的网络，在RPN模块以及检测器中都能学习支持数据与查询数据间的匹配关系。具体来看，本文构建了一个包含多个分支的权重共享框架，其中一个分支用于查询数据，其他的用于支持数据。网络基于Faster RCNN进行改进。

##### 基于注意力机制的RPN网络

​        在基于few-shot学习的目标检测网络中，RPN网络的作用不仅仅要给网络的下一阶段提供优质的候选框以区分背景与前景，还应该过滤掉不属于特定类别的目标对象。如果不给RPN模块提供支持图像信息，RPN会将所有包含目标的框激活，即使框的类别不属于支持图像中特定的类别，这些不同类别目标的负样本将增加后续检测器的分类任务压力。为了解决这个问题，本文提出了Attention RPN结构，通过使用支持数据的信息来过滤掉大部分的背景框和不匹配的类别。

​        本文通过深度的方式来计算支持图像特征映射与查询图像特征映射之间的相似度，然后使用得到的模块进行候选框的生成。通过实验kernel size设成1效果更好，这也验证了**全局特征可以为目标分类提供良好的目标先验**。完成depth-wise卷积后，经过3x3卷积处理，再进行目标分类和框回归。

##### 多重相似度探测器

​        在RCNN框架中，一个RPN模块后面往往会接检测器部分，实现对于候选框进行重新打分以及分类的重要作用。因此，需要检测器具有很强的辨别能力来区分不同的类别。本文提出了新的多重相似度探测器来有效地度量支持对象与查询图像中候选框的相似度。探测器模块包含三个注意力机制模块，全局相关部分学习全局匹配信息，局部相关部分从像素维度以及深度维度对支持和查询目标框进行相关度学习，补充部分则学习一个深度非线性的度量。实验证明这三个部分可以相互结合从而实现更好的表现。

##### 双路对比训练策略

​        一个简易的训练策略是通过构造一个支持数据和查询数据为同类别的训练对匹配同一类别的目标。但是一个好的模型不仅要匹配同一类别的目标，还要能够区分不同类别的目标。因此，本文采用双路对比训练策略。如下图所示，训练策略可以匹配相同类别的同时区分不同的类别。

​        本文通过随机选择一张查询图，然后找到一张同类别目标的支持图片作为正样本，另一张包含另一类别的支持图作为负样本，构建一个训练三元组。在三元组中，只有与正样本类别相同的目标才视为前景，其他都视作背景。

​        在训练阶段，由于只有特定类别的目标才视为前景，即使使用了Attention RPN，还是会有正负样本不均衡的问题。因此本文平衡了查询图片中的候选框与支持图的比例。正样本候选框与正样本支持图对：负样本候选框与正样本支持图对：候选框与负样本支持对为1:2:1，分别选择匹配分数最高的前N、2N、N对并计算所选对上的匹配loss。

​        通过实验验证，当实验设置为2-way 5-shot时效果最佳，且增加多个分支并不能提升甚至会降低指标。本文认为**在训练用于区分不同类别的模型时，使用一个负样本的支持类别就足够了**。

### 实验

​        在实验阶段，本文在不同数据集上比较了本文网络与其他最新的方法。通常我们会在FSOD数据集上训练整个模型，然后对这些数据集进行测试。但是为了公平，本文放弃在FSOD数据集上进行训练，采用了与这些方法相同的训练及测试设置。

#### 训练细节

​        本文的模型在四张Tesla P40 GPU上使用SGD优化策略进行端到端训练，每张卡上查询图像的batch size设置为4。前56000次训练学习率为0.002，后4000次训练学习率为0.0002。采用ImageNet和COCO数据集上的预训练模型能帮助更好地收敛。同时，我们发现过多的迭代次数会损害模型的性能，导致过拟合的问题。通过只训练较深的层使用浅层的特征来避免过拟合问题。查询图像的大小被限制在600到1000范围内。支持图像则先进行外围16像素填充并零填充为正方形后resize成320x320大小。在训练和测试阶段，对同一类别的目标采用平均来融合特征，并把结果送到后面的Attention RPN以及多重相似度探测器中。

#### 与最新研究方法比较

##### ImageNet检测数据集

​        本文基于50way-5shot的检测场景在ImageNet上与LSTD以及RepMet进行了比较。为了对标，我们使用了与他们一样的COCO数据集进行训练，在测试阶段，使用了RepMet中的soft-NMS。在AP50的评价指标下，我们的方法有1.7%的提升。

​        为了展示我们方法的泛化能力，我们直接将FSOD数据集训练得到的模型用在测试集上，AP50得到了41.7%的数值，比在COCO训练集上微调的模型表现的好得多。值得一说的是，我们在FSOD数据集上训练得到的模型能够直接测试集上得到最优的表现而不用在数据集上微调。尽管在FSOD数据集上训练得到的模型在AP50指标下略优于COCO数据集上微调的模型，但是在AP75指标下，我们的模型高了6.4%，这说明FSOD数据集对于Few-Shot目标检测有着明显的提升。将我们的FSOD训练得到的模型在测试集上微调能够获得最好的指标，并且我们的模型在微调前就已经获得了最新最好的指标。

##### MS COCO数据集

​        本文在COCO的minival数据集上将我们方法与Feature Reweighting和Meta RCNN进行了比较。使用他们的数据集划分方法，以VOC数据集的20类目标作为测试类别，将剩下60类目标作为训练类别。我们的模型与Meta RCNN相比AP/AP50/AP75分别有2.4%/1.3%/4.0%的提升。这说明我们的模型具有较强的学习和泛化能力，而且针对Few-Shot场景，学习寻常目标匹配关系比单独学习特定类别间的嵌入更有前景。FSOD数据集训练得到的模型在AP/AP50/AP75上分别有7.9%/12.2%/9.5%的提升。

#### 实际应用

​        本文在不同的现实场景中使用我们的模型来验证它的泛化能力，并进一步应用到了野生企鹅的检测。

##### 全新类别检测

​        考虑以下实际场景：给定没有标签的相册或电视剧中大量图片，任务就是将一种全新的目标从图中标注出来，我们不知道那些图片包含有目标信息且目标可能在图中具有不同的大小以及位置。为了降低劳动成本，一种解决办法就是找到包含目标的少量图片，标注以后再使用我们的方法自动标注剩余的图片集。基于这种场景下，本文使用FSOD的测试集进行了混合测试。

##### 野车检测

​        本文在KITTI数据集及Cityscapes数据集上进行野车检测，并与DA Faster RCNN进行比较，得到了同级别的表现，而DA Faster RCNN是专门为了检测野车设计的，在相关领域使用了更多的训练数据。

#### 更多的类别还是更多的样本

​        本文提出的数据集有大量的目标类别，但是每一类目标的样本数目却很少，我们认为这样的设定更有利于Few-Shot目标检测。将FSOD数据集中与COCO数据集类别相同的样本抽取出来，通过实验得到COCO虽然样本数目更多，效果却更差。这都表明较少的类别数目和过多的样本数目都会妨碍Few-Shot检测，多类别总能帮助任务提升效果。所以，本文认为**类别多样性对于Few-Shot目标检测至关重要**。

### 结论

​        本文提出了一种新的Few-Shot检测网络，并提出了一个新的数据集FSOD。本文的工作在Few-Shot目标检测具有一定的贡献，相信可以衍生出更多值得研究的相关工作。



## 总结

​        论文的贡献主要如下：

- 针对Few-Shot目标检测的实际场景，重新设计了Faster RCNN，将Few-Shot分类等领域的一些成果通过改框架的方法部署到检测领域中，实现不需要微调就可以使用的Few-Shot检测，且效果较好。
- 提出了新的专为Few-Shot设计的数据集，并且通过实验验证了对于Few-Shot任务来说，类别的多样性至关重要，而非样本数量，笔者认为过多的样本数量可能导致“过拟合”从而降低Few-Shot任务的指标。

​        总的来说，这篇论文无论在创新点、工作量上都属上乘，且研究实用性较高，CVPR2020实至名归。
