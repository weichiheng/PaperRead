# Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection

## 论文内容

### Abstract

Object detection has been dominated by anchor-based detectors for several years. Recently, anchor-free detectors have become popular due to the proposal of FPN and Focal Loss. In this paper, we first point out that the essential difference between anchor-based and anchor-free detection is actually how to define positive and negative training samples, which leads to the performance gap between them. If they adopt the same definition of positive and negative samples during training, there is no obvious difference in the final performance, no matter regressing from a box or a point. This shows that how to select positive and negative training samples is important for current object detectors. Then, we propose an Adaptive Training Sample Selection (ATSS) to automatically select positive and negative samples according to statistical characteristics of object. It significantly improves the performance of anchor-based and anchor-free detectors and bridges the gap between them. Finally, we discuss the necessity of tiling multiple anchors per location on the image to detect objects. Extensive experiments conducted on MS COCO support our aforementioned analysis and conclusions. With the newly introduced ATSS, we improve stateof- the-art detectors by a large margin to 50:7% AP without introducing any overhead. The code is available at [code](https://github.com/sfzhang15/ATSS).

### 摘要

目标检测一直由基于锚框的检测器主导了多年，近年来，由于FPN以及Focal Loss的提出，不基于锚框的检测器也越来越热门。本文首先指出基于锚框的检测与无锚框检测的本质区别就在于**如何定义正负训练样本**，这导致了两者之间性能的差距。如果他们在训练时采用相同的正负样本定义，无论是从框回归还是从点回归，最终的表现没有明显的差异。这也表明了如何选择训练的正负样本对于当前的目标检测器来说是非常重要的。本文提出了一种自适应训练样本选择法根据目标的统计特征自动选择正负样本。它大大地提高了基于锚框检测器与无锚框检测器的性能，弥补了两者之间的差距。最后本文讨论了在图像每个位置上平铺多个锚点用来检测目标的必要性。在COCO数据集上通过实验验证了上述的分析和结论。有了新的ATSS，我们在不引入任何开销的情况下，将最新的检测器指标大幅提升至50.7%。[代码](https://github.com/sfzhang15/ATSS)

### 引言

目标检测是计算机视觉领域一个由来已久的课题，目的就是检测出预定义类别的目标。精确的目标检测将对包括图像识别及视频监控等各种应用有着深远的影响。近年来，随着深度卷积神经网络的发展，目标检测开始由基于锚框的检测器主导，一般可以分为单阶段和双阶段方法。两种方法都是先在图像上平铺大量预设的锚点，接着预测类别并一次或多次对这些锚框的坐标进行精炼，最后将这些精炼后的锚框作为检测结果输出。由于双阶段方法相对于单阶段方法由更多锚框精炼的次数，所以前者在计算结果上更加精确，后者则具有更高的计算效率。基于锚框的检测器依然在常规数据集上保持着领先的结果。

由于FPN与Focal Loss的出现，学术上已经开始聚焦于无锚框检测。无锚框检测通过两种方法直接找到目标而不需要预设的锚框。一种方法是先找到一些预定义的或者自学习得到的关键点，然后绑定目标空间位置，这种方法我们称为**基于关键点的方法**。另一种方法是使用目标的中心点或者目标区域来定义正样本，然后预测正样本中心到边界的四个距离，我们将这种方法称为**基于中心的方法**。无锚框方法可以不使用与锚框相关的超参数，并取得与基于锚框的方法相似的性能，使得它们在泛化能力上具有更大的潜力。

在两种无锚框方法中，基于关键点的方法采用标准关键点估计方式，这与基于锚框检测不同，而基于中心的方法则于基于锚框检测相似，它们将中心点视为预设的样本，而非锚框。以基于锚框的单阶段检测网络RetinaNet和基于中心无锚框检测网络FCOS为例，它们主要有以下不同：

- 每个位置设置的锚框，RetinaNet每个位置上会预设几个锚框，而FCOS则是一个锚点一个位置。
- 正负样本定义，RetinaNet使用IOU来定义正负样本，而FCOS则使用空间和尺度的约束来选择正负样本。
- 回归的方式，RetinaNet使用锚框回归最终的输出框，FCOS使用锚点回归最终的输出。

无锚框的FCOS得到了比基于锚框的RetinaNet好得多的效果，上述三个差异中到底是哪个造成性能差距的原因是值得研究的。

本文移除了两种方法中不同的实现细节，公正地研究了两者之前的区别。最终从实验中可以得出，两种方法的本质在于正负样本的定义，这导致了它们最终性能的差异。如果在训练时选择相同的正负样本，无论从锚框回归还是锚点回归，二者都没有明显的性能差异。因此，如何选择正负样本是真正值得进一步研究的。在此基础上，我们提出了一种新的自适应训练样本选择算法，可以基于目标特征自动地选择正负样本。它弥补了无锚框检测方法与基于锚框方法之间的差距。此外，通过一系列的实验我们得出，在每个位置上平铺多个锚框是没有必要的。本文的主要贡献可以总结如下：

- 表明基于锚框检测方法与无锚框检测方法的主要区别就是正负训练样本的定义。
- 提出了一种新的自适应训练样本选择算法，通过目标的统计特征自动选择正负训练样本。
- 证明在每个位置上平铺多个锚框用来检测目标是不需要的。
- 在COCO数据集上获得最新的性能且不需要额外的开销。

### 相关研究

当前的目标检测网络由基于锚框的检测及无锚框检测方法组成，前者包含单阶段与双阶段方法，后者包含基于关键点的方法和基于中心的方法。

#### 基于锚框的检测器

##### 双阶段检测网络

Faster RCNN的出现确立了双阶段基于锚框检测器的优势地位，后续有很多的改进并取得了较好的提升。目前，在标准数据集上，双阶段检测网络依然保持领先。

##### 单阶段检测网络

随着SSD的出现，单阶段基于锚框检测器因计算效率收到广泛关注。SSD在多个尺度的特征映射上展开锚框，并直接在卷积网络上预测目标类别以及锚框偏移量。后续也有很多工作改进单阶段基于锚框网络，并取得了很好的效果。目前基于锚框的单阶段网络能够以更块地推理速度达到非常接近双阶段检测网络地性能。

#### 无锚框检测器

##### 基于点回归的检测器

这类方法首先定位几个预设的或者自学习得到的关键点，再基于关键点生成候选框来检测目标。CornerNet通过一对关键点回归候选框实现目标的检测。Grid RCNN在第二阶段借助FCN对位置敏感的优点来预测网格点，然后基于网格点来确定目标。ExtremeNet基于边框四个点（最上、最下、最左、最有）及中心点实现目标检测。CenterNet扩展了CornerNet的关键点对成三元组，以提升精确率和召回率。RepPoints将目标视为一组关键点，网络学习以一种包围目标空间范围并显示语义上显著的局部区域的方式来重新排列这些关键点。

##### 基于中心的检测器

这种无锚框方法以目标中心（如中心点或者中心部分）为前景定义正样本，然后预测正样本中心到目标边界框四条边的距离。YOLO将图像分为SxS个网格，包含目标中心的网格负责预测改目标。DenseBox使用位于目标中心的一个填充圆来定义正样本，然后预测正样本到目标边界框的四个距离。GA-RPN将目标中心区域的像素定义为正，帮助Faster RCNN候选目标的位置、宽高的预测。FCOS将目标框内的所有位置都视为正样本，并利用四个距离和一个中心分数来检测目标。CSP只将目标框的中心点定义为正样本来预测固定宽高比例的行人。

### 基于锚框检测器与无锚框检测器差异分析

本文采用基于锚框的RetinaNet和无锚框的FCOS进行差异分析。在本节中，将重点讨论三个差别中正负样本定义以及初始回归状态对于网络性能的影响。因此，我们在RetinaNet每个预测位置上放置一个锚框，这与FCOS非常类似。

#### 实验设置

##### 数据集

所有的实验都是在COCO数据集上做的，包含80个类别。按照惯例，trainval135k分支中的115K张图片都被用作训练，minival分支中的5K张图片都用来验证分析。同时我们也会提交主要的结果到测试服务器上，来获得最终在test-dev数据集上的结果。

##### 训练细节

本文将ImageNet上预训练的具有5层特征金字塔结构的ResNet-50作为主干网络。对于RetinaNet，5层特征金字塔的每一层都与一个8S尺度的方形锚框联系，其中S是当前层的总步长。在训练过程中，本文调整了图片大小到800和1333中间。训练使用SGD算法迭代90K次，batch size为16。初始学习率设为0.01，并在迭代60K次和80K次后衰减0.1。

##### 测试细节

图片按照训练阶段一样resize后输入到网络中得到结果，用0.05先滤除大量的背景框，每层特征映射得到前1000个检测结果。再经过每个类别IOU为0.6的NMS得到每张图前一百置信度检测结果。

#### 差异移除

我们将每个定位点只有一个锚框的RetinaNet称为RetinaNet（#A=1），这也与FCOS的配置一样。然而，按照实验结果，FCOS比RetinaNet（#A=1）在指标上要高出几个点，此外，一些新的改进也被应用在了FCOS上，例如将中心移至回归分支，使用GIoU，使用相应步长对回归目标进行归一化。这些改进将FCOS的性能从37.1%提升到37.8%，使得差距变得更大。然而，RetinaNet和FCOS之间的部分AP差距由FCOS中提出或采用的常规改进方法得到，如在网络head中添加GroupNorm、使用GIoU回归损失函数、将正样本限制在gt中、为每层特征金字塔添加一个可训练的标量。这些改进可以同时应用到基于锚框的检测和无锚框检测网络中。我们将上述改进一个一个往RetinaNet上实现从而排除掉网络实现上的差异。这些不相关的差异提高RetinaNet至37.0%，与无锚框的FCOS依然有0.8%的差距。现在，在消除了所有无关的差异后，我们可以很好地探究基于锚框地检测器与无锚框检测器之间的本质差距。

#### 本质区别

在应用完这些通用的改进后，基于锚框的RetinaNet（#A=1）与无锚框的FCOS只有两个区别。一个是检测任务中的分类子任务，即如何定义正负样本。另一个是分类子任务，即从锚框开始回归还是从锚点开始回归。

##### 分类

RetinaNet使用IoU将不同尺度的特征金字塔层的锚框划分为正的和负的，首先将每个目标最好的锚框标出来，IoU大于阈值的样本视为正样本，IoU小于阈值的视为负样本，最后在训练期间忽视其他的锚框。FCOS使用空间和尺度约束来划分不同特征金字塔层的锚点，首先将在gt中的锚点视为候选正样本，然后基于每个特征金字塔层的尺度范围从候选正样本中选择最终的正样本，其他的未选择的锚点则未负样本。FCOS首先利用空间约束条件在空间维度上找到候选正样本，再使用尺度约束条件从尺度维找到最终的正样本。而RetinaNet则利用IoU同时在空间维和尺度维上选择最终的正样本。这两种策略导致了最终正负样本的差异。RetinaNet（#A=1）使用空间和尺度约束条件而非IoU约束条件可以将AP从37.0%提升到37.8%，而FCOS如果使用IoU约束条件不使用空间和尺度约束条件，AP将从37.8%掉至36.9%。这些结果表明，正负样本的定义是基于锚框检测器与无锚框检测器的本质区别。

##### 回归

在正负样本以及确定后，最终目标位置就是从这些正样本中回归得到的。RetinaNet从锚框回归并与锚框有四个偏移量，FCOS则回归得到锚点到边界框的四个距离。这意味着对于一个正样本，RetinaNet的初始回归状态是一个框，FCOS是一个点。由实验结果可以知道，当二者使用相同的样本选择策略，得到相同的正负样本策略时，无论从一个点还是一个框开始回归，最终的性能没用明显的差异。这表明回归的起始状态不是本质差异，而是一个无关差异。

##### 结论

通过这些公平的实验表明，单阶段基于锚框的检测器与基于中心的无锚框检测器的本质区别在于如何定义正负训练样本，这对当前的目标检测具有重要意义，值得进一步研究。

### 自适应训练样本选择算法

在训练一个目标检测器时，我们首先需要定义正负样本来分类，然后使用正样本进行回归。根据上述的分析，前者是关键，而无锚框检测器FCOS则改进了这一步。它引入了一种新的方法定义正负样本，且比传统基于IoU的策略有更好的效果。在它的启发下，我们深入研究了目标检测中最基本的问题：如何定义正负训练样本，并提出了一种自适应的训练样本选择算法。与传统的策略相比，这种方法几乎没有超参数，对不同的设置具有较强的超参数。

#### 描述

以往的样本选择策略都有一些敏感的超参数，比如基于锚框检测器的IoU阈值和无锚框检测器的尺度范围。这些超参数定下来以后，所有的gt检测框都需要按照这样的规则来选择自己的正样本。这样的规则对于大部分的目标适合，但还会忽略一些靶外的目标。因此，不同的超参数设置将会产生非常不同的结果。

为此，本文提出了不需要任何超参数，依靠目标的统计特征来划分正负样本的算法。对于图像上的每个gt样本框，我们先找到它的候选正样本。在每个特征金字塔特征层上，根据L2距离选择中心最接近gt中心的k个锚框。假设有L个特征金字塔层，那么gt框将会有kxL个候选正样本。接着我们计算这些候选框与gt框之间的IoU，并计算IoU的均值及标准差。通过这些统计数据，这个gt框的IoU的阈值为均值和标准差的和。最终，我们将IoU大于或等于阈值的候选正样本作为最终的正样本。值得注意的是，正样本的中心依然限制在gt框中。如果一个锚框被分配给多个gt框，那么选择IoU最高的一个gt，其余的视为负样本。

##### 根据锚框与目标之间的中心距离选择候选目标框

对于RetinaNet来说，锚框与目标中心距离越短，IoU越大；对于FCOS来说，离物体中心越近的定位点将产生更高质量的检测结果。因此，锚框中心与目标中心的距离越小越好。

##### 使用均值和标准差和作为IoU的阈值

目标的IoU均值是该目标对于所有预设的锚框匹配的度量。高的均值说明该目标具有高质量的候选框，IoU的阈值应当设置地较高；低的均值说明目标大部分的候选框质量较低，相应的阈值应该设置地较低。目标的标准差是对于哪层特征映射适合检测该目标的度量。大的标准差意味着存在一个特别适合检测该目标的特征金字塔层，将标准差与均值相加可以得到一个高的阈值，从而只在该层得到正样本。小的标准差意味着有几个特征金字塔层适合该目标，将标准差和均值相加可以得到一个较低的阈值，从而在多个层中找到适合的正样本。使用IoU的均值和标准差之和作为目标IoU的阈值可以根据目标的统计特征自适应地从适当的特征金字塔级别中为每个目标选择足够的正样本。

##### 限制正样本的中心在目标内

中心点在目标外的锚框是较差的候选锚框，会使用目标外的背景参与预测，不利于训练，所有应该排除。

##### 保持不同目标间的公平性

根据统计理论，约16%的样本处于置信度区间。尽管候选锚框的IoU分布不是标准正态分布，每个目标都有大概0.2xkL个正样本数，这与目标的尺度、位置及宽高比无关。相对而言，RetinaNet与FCOS对于较大的目标往往有更多的正样本，导致不同目标间的不公正性。

##### 几乎不用超参数

我们的算法只有一个超参数k，后续的实验证明，k值的变化对算法性能影响不大。ATSS算法可以被认为几乎是无超参数的。

#### 验证

##### 基于锚框的RetinaNet

在RetinaNet（#A=1）上部署我们的算法，分别在AP上获得2.3%，AP50上获得2.4%，AP75获得2.9%，APs上获得2.9%，APm上获得2.1%，APl上获得2.7%的提升。这些提升主要就是基于每个目标锚框的统计特征自适应选择正样本得到的。由于只是改进了正负样本定义方式，所以这些改进可以认为是无消耗的。

##### 无锚框的FCOS

提出的算法同时适用于FCOS的两种版本：精简版和完整版。在精简版中，我们将ATSS的一些想法应用到FCOS中，例如将选择候选正样本的方法替换成我们的算法。FCOS将目标框中的锚点视为正样本，这将导致过多的低质量正样本。相比而言，使用我们的算法在每层特征金字塔层中为每个gt目标寻找top9个候选点。我们的精简版算法已经被加入到FCOS的官方代码中用作中心采样，这使得FCOS的AP从37.8%提升到了38.6%。然而精简版的FCOS依旧存在控制尺度范围的超参数。对于完整版，我们将FCOS中的锚点换成8S尺度的锚框来定义正负样本，然后像FCOS一样从锚点回归目标的正样本。通过实验分别在AP上获得1.4%，AP50上获得1.7%，AP75上获得1.7%，APs上获得0.6%，APm上获得1.3%，APl上获得2.7%的提升。值得注意的是，这两者在空间维度上选择了相同的候选目标，但在尺寸维度上对候选框筛选最终的正样本方式不同。完整版本的ATSS在不同的指标上性能远优于精简版。这表明自适应的方法能够获得更好的效果。

#### 分析

使用本文提出的自适应训练样本选择算法训练目标检测器只设计一个超参数k和锚框的相关设置。

##### 超参数k

我们对超参数k设计了实验来研究其鲁棒性。在实验中分别使用不同的超参数，从实验得到，网络对于k从7至17的变化并不敏感，而过大的k值将会导致网络性能的退化。总的来说，算法引入的超参数k是相当鲁棒的，ATSS几乎可以视为无超参数的。

##### 锚框尺寸

提出的算法还涉及到使用锚框来定义正样本，我们也研究了锚框尺寸的影响。在之前的实验中，每个位置放置一个8S（S为当前特征金字塔层的总步长）大小锚框。本文测试了不同尺度的锚框对于性能的影响，结果变化不大。此外，还进行了几种宽高比的实验，性能影响也不大。上述实验表明，算法对于不同的锚框设置具有较好的鲁棒性。

#### 比较

本文的网络与多个最新的网络进行比较，得到了非常好的效果。由于我们的方法是改变正负样本的定义，所以它可以兼容现有的大部分网络。

#### 讨论

上述的实验都是基于每个位置一个锚框的RetinaNet做的，但是原始的RetinaNet每个位置上放置了9个锚框。在不使用ATSS算法的情况下，9个锚框比1个锚框性能要好很多，这说明对于传统的IoU样本选择策略来说，放置更多的锚框更加有效。但是在使用本文的算法以后，放置更多的锚框或者改变锚框的尺寸对于最终的性能表现影响不大。这说明只要选取适当的正样本，无论在每个位置放置多少个锚框，结果都是一样的。对于本文提出的算法来说，每个位置放置多个锚框是一种无用的操作，需要进一步的研究，从而发现其正确的作用。

### 结论

在本篇工作中，我们提出单阶段基于锚框检测器与基于中心的无锚框检测器间本质区别就是正负训练样本的定义。这说明了在目标检测训练中如何选择正负样本是至关重要的。受到启发，本文深入研究了该问题，提出了自适应训练样本选择算法，根据目标的统计特征自动划分正负训练样本，弥补了基于锚框检测器与无锚框检测器间的差距。接着我们讨论了在每个位置上放置多个锚点的必要性，表明在使用本文算法的情况下这是个多余的操作。同时经过在COCO数据集上大量实验，证明该方法可以不引入任何额外开销实现最新的性能。

## 总结

论文的主要贡献如下：

- 针对FCOS比RetinaNet涨点的现象进行深入分析，得到了在公平条件下，影响指标的主要因素就是对于正负样本的定义方式。
- 提出了一种基于目标匹配候选框的统计特征自适应选择正负训练样本的算法，并在该算法的环境下验证了在单个位置上过多放置锚框是徒劳的。

这篇论文是一篇条理严密的论文，实验上一环扣一环，找到问题深入研究，再提出新方法并用实验充分证明。自适应正负训练样本选择算法可以在代价极小的情况下替换掉正负样本定义模块，使得网络效果得到提升。

