# Semi-Supervised Semantic Image Segmentation with Self-correcting Networks

## 论文内容

### Abstract

Building a large image dataset with high-quality object masks for semantic segmentation is costly and time consuming. In this paper, we introduce a principled semisupervised framework that only uses a small set of fully supervised images (having semantic segmentation labels and box labels) and a set of images with only object bounding box labels (we call it the weak set). Our framework trains the primary segmentation model with the aid of an ancillary model that generates initial segmentation labels for the weak set and a self-correction module that improves the generated labels during training using the increasingly accurate primary model. We introduce two variants of the self-correction module using either linear or convolutional functions. Experiments on the PASCAL VOC 2012 and Cityscape datasets show that our models trained with a small fully supervised set perform similar to, or better than, models trained with a large fully supervised set while requiring ~7x less annotation effort.

### 摘要

为语义分割制作一个具有高质量目标掩膜的数据集是非常耗时耗力的工作。在本文中提出了一个半监督框架，它只使用一小组全监督图片（包含语义分割标注和框标注）以及一组只包含检测框标注的图像（本文称为weak set）。我们的框架使用一个辅助模型为weak set生成初始分割标记训练主体分割模型，使用自修正模块在训练阶段用越来越精确的主体分割模型改进生成的标注。我们引入了分别使用线性函数或卷积函数的两种自修正模块。在VOC2012和Cityscape数据集上的实验证明我们的模型使用小部分全监督数据集训练后，性能接近甚至超过在大量全监督数据集上训练的其他模型，相比而言，我们需要少得多的标注。

### 引言

深度卷积神经网络在很多计算机视觉任务上取得了成功，其中包括图像分类、目标检测、语义分割、姿态识别、人脸关键点定位等。然而所有的这些成果都是基于大量的标记图像数据集。在这些任务中，语义分割是数据标注方面成本最高的任务之一。例如，标注一张分割图片的耗时往往是标注检测图片的8倍，是分类图片的78倍。因此，大部分的图像分割数据集的量级要小于图像分类数据集。本文采用一个半监督方法基于代价更小的检测标记训练，从而缓和语义分割的数据需求。这种方法降低了标注检测框中目标掩膜的需求。当前最先进的半监督方法通常依赖手工制作的启发式推断目标框内目标的掩膜。相反，我们提出了一个框架，在半监督的模式下使用 一小组全监督图像（带有目标掩膜及目标框）和一组weak图像数据集（只有目标框标注）训练语义分割模型。全监督数据集用来训练一个在weak set上生成目标掩膜的辅助分割模型。接着使用得到的数据集训练主体分割模型。为了适应由辅助模型生成的掩膜标注的不确定性，主模型采用了概率分割模型。通过制定训练，使在训练过程中提供给主体模型的标记从最初辅助模型给予的标记随着主体模型的优化慢慢变成主体模型自身得到的更准确的标记。因此，我们将自己的框架称为一个自修正分割模型，它在现有目标掩膜概率模型基础上改进了弱监督标注。

本文提出了两种自我修正机制。首先，受Vahdat的启发，我们使用一个线性函数结合辅助模型预测和主模型预测。这种简单同时有效的方法是将分割标注上的加权KL散度最小化到辅助模型和主模型上的自然结果。但是这种方法需要定义一个权重，且最优值需要在训练期间不断改变。因此，本文提出了第二个自适应的自我修正机制。我们使用CNN来学习如何结合辅助模型和主模型在weak set上预测目标的分割标注。这种方法不用对权重进行调整。在VOC和Cityscapes数据集上的实验表明，我们的模型使用小部分全监督数据集训练，性能可以与在大量全监督数据集上训练得到的其他模型像媲美（有时效果更好）。

### 相关研究

#### 语义分割

全卷积网络已经成为图像语义分割不可缺少的模型。许多全卷积网络的成功应用基于**空洞卷积**（不降低图像尺度的情况下提升网络的感受野）、**密集条件随机场**（无论是作为后处理还是插入模块）。近期的研究集中在基于编码器-解码器的模型上，利用编码器提取远距离信息，再将输出传递给生成高分辨率分割预测的解码器网络。SegNet、U-Net、RefineNet就是这种模型的示例，它们使用不同的机制将信息从编码器传递到解码器。另一种获得远程上下文信息的方法是空间金字塔池化，ParseNet将全局上下文信息特征添加到空间信息中，DeepLabv2使用空洞空间金字塔池化，PSPNet从多个尺度上引入空间金字塔池化来解决分割问题。尽管可以使用其他的模型，我们还是选用了DeepLabv3+作为我们的分割模型，因为使用简单的阶乘模型，它的性能优于以前基于crf的DeepLab模型。DeepLabv3+将DeepLabv3的主干网络换成Xception网络并将其与一个简单的两层解码器堆叠在一起，该解码器使用来自编码器的低分辨率特征映射。

#### 鲁棒性训练

在检测标记信息中训练分割模型可以视为一个对带噪声标记实例进行鲁棒学习的问题。之前关于鲁棒性学习的研究主要集中在输出变量较少的分类问题上。再此背景下，一个通常的简化假设是将输出标注上的噪声视为独立于输入标注上的。然后，最近的工作已经基于每个实例的信息解除了这个约束。Xiao使用简单的二元指示器来判断每个实例是否拥有带噪声的标注。所有的研究都是基于图像分类问题，尚未应用于图像分割。

#### 半监督语义分割

本文的重点是利用边界框标注的数据集训练深度分割CNN网络。本文的工作与以前方法在两个方面不同：

- 将人为设定的规则替换为一个辅助CNN从weak set中提取概率分割标注。
- 在训练中使用自修正模块来修正辅助CNN与主分割模型间的不匹配。

除了边界框标注外，分割模型还可以使用其他形式的弱标注，例如图像像素级、图像标签级、涂鸦、点标注或者网络视频。目前，对抗学习的方法也针对这个问题提出了一些建议，我们的框架对于其他形式的监督或对抗性训练来说是无消耗的，可以与方法并存。

### 方法

我们的目标是使用两个数据集在半监督的设置下训练一个语义分割网络，一个小的全监督数据集（包含图像、分割标记、检测框标记），一个weak数据集（包含图像和目标边界框）。整个框架包含三个模块：

- 主分割模型生成给定图像的目标语义分割。
- 辅助分割模型在给定图像和边界框的情况下输出分割。该模型为weak set中的图像生成分割，并参与到主模型的训练中。
- 自修正模块将weak set中经过辅助分割模型和主分割模型的分割输出进行精炼。

辅助模型和主模型都是基于DeepLabv3+，但是我们的框架是通用的，可以使用任何现有的分割模型。

#### 辅助分割模型

使用检测框标记的半监督分割训练的关键挑战就是如何推断出检测框内目标的分割。现有该问题的解决方案主要依赖于基于GrabCut原则定义的人工规则或者标签迭代优化机制。后一个过程一般在图像提取分割和使用边框信息精炼标注间迭代。这些方法中主要存在的问题有：

- 检测框的信息没有直接用来提取分割掩膜。
- 由于人工设计可能导致优化问题。
- 当多个目标框重叠时可能造成分割模糊。

本文设计了一个辅助分割模型，在给定图像和目标边界框的情况下，生成逐像素分割标记。这个模型能够轻松地在全监督数据集上训练，同时可以作为图片的训练信号。在推理阶段，图像和边界框都被输入到网络中用来获取分割标记分布。设计辅助分割模型时，我们主要注意点在于基于编码器-解码器的分割网络中编码器通常依赖图像分类模型进行初始化。通过使用大型分类数据集中学到的特征，可以帮助提升分割性能。为了保持相同的优势，我们增加了一个基于编码器-解码器的分割模型，使用一个平行的边框编码器网络来嵌入不同尺度的边框信息。边框编码器的输入为表示目标边界框二值化掩膜的3维张量，输出的维度则代表目标维度。输入的掩膜张量会被resize成目标维度，接着通过一个3x3的卷积层和sigmoid激活层。结果张量可以解释为一个注意力特征，与分割编码器生成的特征映射在元素维度上相乘。如DeepLabv3+架构中，本文在两个不同的尺度上进行了上述的操作。对于每个尺度，生成一个注意图，并将其在元素维上与对应的特征映射相乘，再送入解码器。对于一张WxHx3的图像，我们使用一个WxHx（C+1）维度的二值化掩膜来表示C+1类目标的边界框。如果像素点在背景掩膜上为1，那么它没有被任何边界框覆盖。辅助模型在全监督数据集上使用交叉熵loss训练。

#### 无自我修正

从经验上观察到，本文的辅助模型性能优于没有使用边界框新的的分割模型。这主要是因为边界框信息在推理阶段引导辅助模型在检测框内寻找目标。训练主模型最简单的方法就是使用全监督数据集中的gt标注以及辅助模型在weak set上生成的标注。相对于这个无自我修正版本，自我修正模型仅仅只是复制了辅助分割模型的预测。训练的loss由两部分组成，一部分为二值化的交叉熵loss，第二部分为与辅助网络生成带软概率标签的交叉熵。辅助网络的参数是固定的。我们将这种方式称为无自我修正模型，它直接依赖辅助模型利用weak set里面的样本训练主模型。

#### 线性自我修正

本文依靠辅助模型来预测目标框中的目标分割。但是，这个模型只使用全监督数据集训练，不会在weak set中获得收益。最近的一些研究通过结合来自weak set的信息，即使用主模型（在全监督数据集和weak数据集上训练）来获得更准确的标签分布。Vahdat引入了一个正则化的期望最大化算法，它使用KL散度的线性组合为常规分类问题推断缺失的标签分布。推导出来的分布应该同时满足由辅助模型生成的标注和主模型生成的标注分布。但是，由于主模型在训练早期无法准确地预测分割掩膜，所以这两项使用一个正的比例因子重新加权。得到的结果作为两个分布的加权几何平均。

在训练中，通过调整比例因子，可以将更新的权重从辅助模型向主模型预测结果偏移，即在训练中由大值减小为小值。这种修正模型称为线性自我修正模型，因为它使用的解决方案是KL散度的线性组合，用以推断潜在的分割标注分布。再训练过程中，随着主模型的参数优化，通过比例因子使得自修正机制偏向于主模型。

#### 卷积自我修正

线性自我修正的一个缺点是在训练过程中需要修正比例因子。在本节中，我们提出了一种新的方法，通过学习自修正机制的卷积网络来替换线性函数，克服了这一困难。网络会在训练主模型时动态调整机制，如果主模型可以精确地预测标注，那么网络可以将它的预测转向主模型。这个小网络接受来自主模型和辅助模型的输出，然后输出一个新的阶层分布。卷积自修正子网络包含两个卷积层，两个卷积层都使用3x3的内核及ReLU激活层。第一层输出为128个特征映射，第二层基于数据集中目标类别输出特征映射。

现在的挑战就是训练卷积子网络，使得它的预测的目标分割比主网络或辅助网络都要准确。为此，我们在目标函数中引入了一个附加项，在训练子网络时使用全监督数据集，主模型则使用全部数据集训练。由于卷积子网络的参数是随机初始化的，所以在训练的前期无法准确地预测分割标注，为了解决这个问题，本文提出以下预训练过程：

- 辅助模型的初始化训练：和以前的自修正模型一样，我们需要对辅助模型进行训练。全监督数据集的一半用来初始化训练。
- 卷积自修正网络的初始化训练：使用全监督数据集训练主模型和卷积自修正模块。
- 主训练阶段：全部的数据集用来训练

在第一阶段只使用一半全监督数据集的原理是防止在后续的训练阶段卷积自修正网络预测只依赖辅助训练模型的输出。为了克服这个训练问题，我们使用另一半全监督数据集帮助卷积自修正模块学习如何有效地结合主模型和辅助模型的输出。

### 实验

在本节中，我们使用VOC 2012和Cityscapes数据集来测试我们提出的模型。两个数据集都包含分割和检测框的标注。我们将完整的数据集标注分为两部分来模拟全监督和半监督的设置。使用mIoU在不同类别中测试模型的性能。

##### 训练

我们将DeepLabv3+的tensorflow版本作为主模型，初始学习率为0.007，且使用在ImageNet数据集上预训练了30000次的Xception-65作为预训练模型。其它的一些参数，我们使用其他作者推荐的标准设置。在评估阶段，我们对图像进行翻转和多尺度处理。使用了4张GPU，每张GPU4张图片。在实验中我们定义了以下基准：

- 辅助模型：通过给定的图像和边界框来预测图像的语义分割标注。由于使用了边界框信息，所以它的预期性能应优于其他模型。
- EM固定基准：由于我们的线性自修正模型来自一个正则化的EM模型，我们与另一个基于EM的模型进行比较。为了公平比较，我们在DeepLabv3+上实现了他们的EM固定基准。这个基准达到了最佳的半监督学习效果。

对于线性自修正模块，通过控制KL散度偏置的权重，大的权重偏向于辅助模型，小的权重偏向于主模型。我们研究了不同具有指数衰减的初始值和结束值，最终发现，起始值为30，最终值为0.5时对于两个数据集都有很好的效果。这个参数设置是鲁棒的，因为对这些值进行微调几乎没有大的影响。

#### VOC数据集

在本节中，我们在VOC 2012上对模型进行了评估。数据集由1464张训练图像、1449张验证图像、1456张测试图像组成，分割包含20个目标前景类和一个背景类。辅助数据集包含9118张训练图像，我们认为其中包含少量的噪声。在这个部分，我们的训练主要在训练集和辅助数据集上，测试在验证集上做，最好的模型则提交到线上评估服务器上测试测试集。本文测试了不同全监督数据集比例对于模型不同变体的性能，通过实验可以得出几个结果：

- 即使使用200张图像的训练集，辅助模型在提供边界框的前提下也能很好地预测分割标注。这说明模型能够在weak set无分割标注情况下提供较好地训练信号。
- 线性自修正模型通常比无自修正模型表现得更好，这也符合我们得想法，即结合主模型和辅助模型来推断分割标注，可以更好地训练主模型。
- 卷积自修正模型性能与线性自修正模型相当甚至更好，同时它消除了训练过程中调整参数的必要。

在测试中，我们的模型由于其他的模型。奇怪的是，半监督模型的表现要由于全监督模型，对于这个现象，我们假设了两种可能的解释。首先，9k张辅助集中标注噪声对于Vanilla DeepLabv3+的性能有负面影响。作为证据，我们找到了一些辅助模型标注比gt标注更恰当的情形。第二则是标注非确定地显式建模和自修正也可能带来性能的提高。我们在VOC 1.4k的数据集上分别训练了全监督模型和半监督模型，最终半监督的表现要好于全监督。这表明用鲁棒损失函数建模噪声并允许自我修正能显著提高分割模型的性能。这与已被证明对于边缘检测有效的自修正方法是一致的，并与常规用来以单交叉熵训练模型的分割目标形成对比。不幸的是，我们无法在最新的DeepLabv3+上实现这些效果好的方法，唯一的例外是EM固定基准。最终我们在DeepLabv3+上实现了较好的效果。对于实验结果的复查表明我们的工作优于以往的工作，因为我们的半监督模型优于全监督模型，而以往的工作没有实现这一点。

#### Cityscapes数据集

在本节中，我们将评估模型在Cityscapes数据集上的表现，其中包含车载不同季节下的图片。这个数据集有很高质量的标注，但是有些实例被少标记或者过多标注了。它包含2975张训练集，500张验证集和1525张测试集，包含19个前景分割目标类别。然而，其中八个类别是平面或者建筑的标注，很少有这种边界框覆盖整个场景的目标类别。为了建造一个类似VOC的分割数据集，我们只采用了其中11类目标。由于修改了标注，所以我们只在提交了验证集上的测试结果，因为服务器上的测试集对所有类别进行评估。在训练中我们不适用数据集中粗略标注训练集数据。通过实验可以知道我们模型的有效性。

### 结论

本文提出了一个使用小组全监督数据集和一组弱标注（仅标框）的半监督框架训练深度卷积神经网络分割模型。我们引入了两种机制使得主模型能够修正辅助模型提供的弱标注。提出的自修正模型使用线性或者可训练的卷积方式结合主模型和辅助模型的预测。实验证明我们的框架在VOC及Cityscapes数据集上效果优于以往的半监督模型。我们的框架可以用于实例分割任务，但是我们将进一步的研究留给未来的工作。

## 总结

本文基于半监督模式搭建了一个框架，通过少量全监督数据集和大量弱监督数据集实现对于主模型的训练，达到完全使用全监督数据集训练的效果，甚至更好。提出两种模式自修正模块，有效地结合了主模型和辅助模型的预测，达到了较好的效果。
