# RepPoints: Point Set Representation for Object Detection

## 论文内容

### Abstract

Modern object detectors rely heavily on rectangular bounding boxes, such as anchors, proposals and the final predictions, to represent objects at various recognition stages. The bounding box is convenient to use but provides only a coarse localization of objects and leads to a correspondingly coarse extraction of object features. In this paper, we present RepPoints (representative points), a new finer representation of objects as a set of sample points useful for both localization and recognition. Given ground truth localization and recognition targets for training, RepPoints learn to automatically arrange themselves in a manner that bounds the spatial extent of an object and indicates semantically significant local areas. They furthermore do not require the use of anchors to sample a space of bounding boxes. We show that an anchor-free object detector based on RepPoints can be as effective as the state-of-the-art anchor-based detection methods, with 46.5 AP and 67.4 AP 50 on the COCO test-dev detection benchmark, using ResNet-101 model. [Code](https://github.com/microsoft/RepPoints)

### 摘要

现代的目标检测很大程度上依赖于矩形边界框，比如在不同识别阶段使用锚框、候选框、最终预测来代表目标。使用边界框虽然方便，但只能实现目标的粗糙定位，导致只能提取目标的粗糙特征。本文提出了RepPoints（representative points），使用一系列样本点来更好地表述目标，对于定位以及识别都很有效。给定训练的gt定位和目标识别，RepPoints学会自动按照目标的空间区域及语义上显著区域重新排列样本点。此外，它不需要锚框来抽样候选框的空间。我们证明了基于RepPoints的无锚框检测能够达到最好的基于锚框检测器指标，使用ResNet-101模型，在COCO上分别得到了46.5的AP和67.4的AP50。[代码](https://github.com/microsoft/RepPoints)

### 引言

目标检测的目的是检测出图片中的目标并且提供他们的类别。它是计算机视觉中最基本的任务之一，是许多视觉应用的关键组成部分，例如实例分割、人体姿态分析、视觉推理等。近年来，目标检测问题的重要性和深度卷积神经网络的快速发展使得目标检测问题取得了长足的发展。在目标检测过程中，边界框是处理过程中最基本的要素，是图片中矩形区域。它们在目标检测中始终贯穿全过程，从锚框到候选框，再到最终的预测。通过这些候选框来提取特征，并用来目标分类和位置回归。边界框之所以被广泛应用，部分原因是目标检测性能的通用度量，它计算了目标的估计框与真实框之间的重叠。另一个原因是深度网络的特征提取很方便，由于它矩形形状，很容易将一个矩形窗口细化为一系列单元矩阵的集合。尽管边界框方便计算，它们只提供了粗糙的目标定位，不符合目标的形状和姿态。从一个边界框的规则单元中提取出来的特征很可能会被背景信息或者包含少量语义信息的无用前景区域严重影响，从而导致提取出来的特征质量差，降低目标检测的分类表现。

本文提出了一种新的方法（RepPoints），提出更精细的定位并帮助分类。RepPoints通过一组点学习自适应地将自己定位在目标上，以限制目标空间范围并指示出语义显著的局部区域。RepPoints的训练由目标定位和目标分类共同驱动，从而实现RepPoints与gt边界框紧密地结合并引导检测器对目标进行正确的分类。这个自适应和可微的表述可以在目前目标检测器的不同阶段中使用，且不需要使用锚框对边界框进行区域采样。RepPonits与目前目标检测中非矩形表示方法不同，后者都是自底向上的方式构建的。这些自底向上的表述识别出单个点（边界框的角或者目标的骨架）再使用人工设计的聚类方法将它们导入目标模型中。它们的表述要么是同轴的（例如边界框），要么则需要目标的gt掩膜作为额外的监督。相比而言，RepPoints采用**自上而下**的方式学习输入目标的特征，允许进行端到端的训练，在不需要多余的监督条件下得到更精细的定位。将双阶段目标检测网络中所有的卷积边界框表述（包括锚框、候选框、最终预测）换成RepPoints后，我们开发出了一个简单有效的无锚框目标检测器，使用ResNet-101模型，不使用多尺度训练测试在COCO上得到42.8AP和65.0AP50，使用多尺度训练测试在COCO上得到46.5AP和67.4AP50。提出的无锚框检测器不仅超越了现今所有的无锚框检测器，而且能与最先进的基于锚框基准相媲美。

### 相关研究

#### 目标检测问题中的边界框

在目标检测任务中，边界框一直是目标表述的主要形式。一方面的原因是，边界框标注简单，没有歧义，并能够为后续的识别过程提供足够准确的定位。这也是为什么主流数据集都采用基于边界框的标注和评估。反过来，这些数据集促使目标检测方法使用边界框作为它们基础表述，以便与评估协议保持一致。另一个原因则是无论是深度学习时代还是早期，几乎所有的图像特征提取器都是基于规则的网格形式输入图像块。因此，使用边界框表述来实现特征提取是很方便的。尽管RepPoints的提议有着不规则的形式，它可以服从于便捷的特征提取。我们的系统将可变卷积与RepPoints结合在一起，它很自然地与RepPoints结合在一起，因为它从几个样本点的输入特征中聚合信息。此外，RepPoints可以很容易地生成矩形的伪框作为新的表述，在目标检测数据集中使用。

#### 现代目标检测网络中的边界框

迄今为止，性能最好的目标检测器通常遵循多阶段识别模式，而边界框表述则几乎出现在所有的阶段：

- 预定义或者学习得到的锚框，作为边界框空间上的假设
- 在连续的识别阶段作为精炼的候选目标
- 作为最终的预测

在现代目标检测网络中的所有阶段中，边界框表述都可以用RepPoints来替换，从而得到一种更有效的新目标检测网络。更具体的说，锚框被中心点取代，它是RepPoints中一种特殊配置。提取候选框和最终定位目标被替换成RepPoints提案和最终目标。由于使用中心点来表述初始目标，新的目标检测网络是无锚框网络。与基于锚框的检测网络相比，使用起来更加便捷。

#### 目标检测的其它表述

为了解决矩形边界框的限制，有很多研究致力于更灵活的目标表述，如用于行人检测的椭圆表述、更好处理旋转变化的旋转边框。

其它的工作目的则是以自底向上的形式表示目标。早期自底向上表述包括DPM和Poselet，近期自底向上的目标检测方法被深度网络开发。CornerNet首先对目标左上角和右下角进行预测，然后使用特殊的配对方法获取目标的边界框。然而，两个相对的角点本质上还是矩形边界框。ExtremeNet在gt掩膜标注的监督下定位x和y方向目标的极值点。总的来说，自底向上的检测器得益于更小的假设空间（比如，CornetNet和ExtremeNet都是检测2维的点而不是直接检测一个4维的边界框）和更精细的潜在定位。但是，它们也有局限性，比如依赖于人工设定的聚类或者后处理过程，从检测点组合成目标。与这些自底向上的工作类似，RepPoints也算灵活的目标表述。但是表述以一种自上而下的方式构造得到，而不需要人工设计聚类过程。RepPoints可以自动学习极限点和语义关键点，而不需要gt边界框的监督，与ExtremeNet需要额外的目标掩膜来监督不一样。

#### 目标识别中的形变建模

视觉识别中最基本的挑战之一就是识别具有多种形态变化的目标。为了模拟这种变化，一种可能的解决方案就是自底向上组合低级成分组件，这方面的典型检测器包括DPM和Poselet。另一种选择则是自上而下进行模型的隐式地转换，在输入的特征上应用一个轻量的网络，要么是全局，要么是局部。RepPoints受这些方法启发，尤其是自上而下的形变建模方法。主要的区别在于，除了提取语义特征外，本文还致力于开发一种灵活的目标表述进行精确的几何定位。相比之下，可变卷积和可变ROI采样方法只是为了改进特征提取。后面也验证了可变ROI采样方法无法获取目标精确的几何定位。在这个意义上，我们扩展了以往几何建模方法中自适应样本点的使用，为了目标更好的定位。

### RepPoints表述

首先回顾边界框表述及其在多阶段目标检测中的使用，接着描述RepPoints表述及其与边界框的区别。

#### 边界框表述

边界框是编码目标空间位置的一种4维表述，B = (x,y,w,h)。由于使用简便，现代目标检测网络在检测各个阶段都严重依赖边界框来表述目标。

##### 多阶段目标检测网络综述

 效果最好的目标检测网络通常采用多阶段识别模式，对象的定位在多阶段中逐步细化。初始给定锚框一系列假定的尺度和宽高比，总的来说，在大的4维假设空间上，通过密集的锚框可以获得高覆盖率，比如RetinaNet在每个位置上放置45个锚框。对于一个锚框来说，在其中心点的图像特征被视为目标特征，再利用该特征生成锚框的目标置信度评分，并通过边界框回归过程得到精炼后的边界框（S1）。在第二阶段，通常通过RoI pooling或RoI Align从精炼后的边界框中提取出精炼的目标特征。对于多阶段方法，同样在边界框回归阶段使用精炼的特征生成中间精炼候选边界框（S2）。在生成最终的边界框目标前，可以多次重复该阶段。在该框架中，边界框回归在逐步精炼目标定位和目标特征中起到了关键作用。

#### RepPoints

如上面所述，4维边界框是目标定位的粗糙表述。边界框表述只考虑目标的矩形空间范围，不考虑能够用来更精确地定位目标、提取更好的目标特征的目标形状、姿态及语义上重要的局部区域位置。

为了克服上述限制，RepPoints采用了一组自适应样本点。

##### RepPoints精炼

逐步精炼边界框的定位以及特征提取是多阶段检测方法成功的关键。这种精炼可以简单的表示为加上一个偏置。值得注意的是，在RepPoints的精炼过程中，偏移量在相同尺度上，所以这种精炼不会面临边界框回归参数之间尺度差异的问题。

##### RepPoints与边界框的转换

为了在训练RepPoints的过程中利用好边界框标注的优势，以及对基于RepPoints方法的目标检测网络进行评估，我们需要将RepPoints转化为边界框。我们使用一个预定义的转换函数T来表示这个过程：Rp->Bp，Rp是目标P的RepPoints，T(Rp)是伪框。

为了实现该目的，我们考虑了三个转换函数：

- T=T1：Min-Max函数。在两个轴上执行最小最大值运算来决定Bp，相当于采样点上的边界框。
- T=T2：局部Min-Max函数。在两个轴上对样本点的子集进行最小最大操作，得到矩形框Bp。
- T=T3：基于矩的变换函数。RepPoints样本点的均值和标准差被用来计算矩形框Bp的中心点和尺度，尺度会乘上全局共享可学习参数。

这些函数都是可微的，允许嵌入到其他目标检测系统中端到端训练。在我们的实验中，它们的效果都很好。

##### RepPoints学习

RepPoints的学习由目标定位损失和目标识别损失共同驱动。为了计算目标的定位损失，我们首先使用前面讨论的转换函数将RepPoints转换成伪框，再计算伪框与转换得到的伪框间的差别。在我们的系统中，使用左上角和右下角的smooth L1 loss来衡量定位损失。使用smooth L1 loss不需要调整计算边界框回归矩阵之间距离时不同loss的权重。

### RPDet：无锚框检测器

我们设计了一种无锚框目标检测器，它利用点来替代边界框作为基本表述，在多阶段过程中，目标的表述过程如下：

目标中心经过第一阶段RP精炼得到RepPoints提案（S1），经过第二阶段RP精炼得到RepPoints提案（S2），最终经过最后的RP精炼得到RepPoints目标。

本文的RepPoints Detector(RPDet)是基于可变卷积的双阶段检测网络构造的。在本节中，我们将介绍RPDet的设计，并讨论其与先有目标检测器的关系及区别。

#### 基于中心点的初始目标表述

在目标检测的初始阶段，主要采用预定义的锚框来表示目标，而本文跟随YOLO和DenseBox的步伐，使用中心点作为目标的初始表述，从而产生了一个无锚框的目标检测器。采用中心点表述的一个好处就是，与基于锚框的对像相比，中心点表述的假设空间更小。基于锚框的方法通常需要多宽高比以及多尺度实现对于四维假设空间的密集覆盖，而基于中心点的方法更容易做到假设空间的覆盖。事实上，所有的目标都有位于图像中的中心点。然而，基于中心点的方法也有特征映射中两个不同目标在同一位置上造成识别目标模糊的问题，这限制了该方法在现代目标检测器上的应用。在以往的工作中，解决办法主要依靠在每个位置上放置多个目标，这又导致了归属模糊的问题。在RPDet中，我们发现使用FPN结构能够大大地缓解这一问题，原因如下：首先，不同尺度的目标将被分配到不同图像特征层，这意味着具有不同尺度但具有相同中心位置的目标。其次，FPN对于小目标有高分辨率的特征映射，这也降低了两个目标中心在同样的特征点上的概率。当我们使用FPN以后，只有1.1%的目标存在中心点位于同一位置的问题。值得注意的是，中心点表述可以视作RepPoints的一种特殊配置，即只有一个固定样本点被采用，从而在整个检测框架中保持一致的表述。

#### RepPoints的使用

RepPoints在我们的目标检测系统中作为基本目标表述。从中心点出发，通过对中心点的偏移量回归，得到第一组RepPoints点。学习得到这一组点的目的主要有：

- gt边界框与诱导伪框左上角和右下角的距离损失
- 后续阶段中目标识别的损失

第二组RepPoints点表示最终的目标定位，由第一组RepPoints精炼得到。第二组RepPoints由点距离损失驱动，目的是学习更精确的目标定位。

#### 可变卷积相关内容

可变RoI采样方法在目标检测的作用与提出的RepPoints不同，基本上讲，RepPoints是目标的几何表述，而可变RoI采样方法则三为了学习目标更强的外观特征。事实上，可变RoI采样不能学习代表目标精确定位的样本点。同时，我们注意到可变RoI采样能够作为RepPoints的补充。

#### 主干网络及头部算法

我们的FPN主干从阶段3（下采样8倍）到阶段7（下采样128倍）生成5个特征金字塔层，头部算法由两个不共享参数的子网络组成，分别实现定位（RepPoints）和分类。尽管我们的方法使用了双阶段定位，它比单阶段的RetinaNet更有效。由于层参数共享，额外的定位阶段只引入了很少的开销，而无锚框设计减少了最终分类分支的负担，从而略微减少了计算量。

#### 定位/分类目标任务

定位有两个阶段：第一阶段中根据目标中心点的假设空间生成第一组RepPoints，第二阶段从第一组RepPoints中精炼出第二组RepPoints。在这两个阶段中，训练中只给定位部分分配正样本的假设空间。第一阶段中，满足以下两个条件则为正样本：

- 该特征映射在的特征金字塔层的尺度与一个gt目标的log尺度相等。
- 该gt目标的中心点在特征映射中。

第二阶段中，如果第一阶段得到的RepPoints满足以下条件则为正样本：

- 诱导的伪框与一个gt目标IoU大于0.5。

分类只对第一组RepPoints进行，当诱导的伪框与gt目标IoU大于0.5则为正样本，小于0.4为负样本，其他忽略。分类训练采用Focal loss。

### 实验

#### 实验设置

我们在COCO数据集上测试了RPDet框架，所有的消融实验都是使用Resnet-50，在minival验证集上验证。检测器在4张GPU上使用SGD训练（每张卡两张图片），使用在ImageNet上预训练好的模型进行初始化。训练时采用随机翻转，测试时采用NMS来做后处理。

#### 消融实验

##### RepPoints vs. bounding box

为了证明提出的RepPoints的有效性，我们提出的RepPoints与基础检测器进行了比较，其中所有的RepPoints都被规则的边界框所取代。初始目标表述采用4的尺度以及1：1的宽高比，如果锚框与gt目标之间IoU大于0.5则为正样本。RepPoints的两个阶段被换成边界框回归。使用标准的边界框回归方法进行几何上的精炼，采用3x3网格点的RoIAlign方法进行特征提取。其他的设置与RPDet方法中设置相同。使用基于边界框的方法得到36.2的mAP，表明采用的是一个很强力的目标检测器。在使用RepPoints替换目标边界框表述后，ResNet-50和ResNet-101上分别得到2.1和2.0的mAP提升，说明RepPoints表述相对于目标检测边界框的优势。

##### RepPoints学习的监督来源

RPDet第一阶段的RepPoints由目标定位损失和目标识别损失（梯度来自后面部分）共同驱动，它表示了第一阶段的目标。如前所述，描述目标的几何定位是表征方法的一项重要职责，在没有目标定位损失的情况下，现有的表征方法很难完成这一任务，因此导致目标检测网络性能急剧下降。对于RepPoints来说，我们发现在移除目标定位监督以后，mAP大幅下降了4.5个点，这表明了目标表征方法中描述对象几何定位的重要性。利用目标识别损失可以帮助RepPoints在目标上定位更具有语义信息的点，从而实现对目标更精细的定位，提升为后续的识别阶段提供的特征。注意，目标识别反馈不能使得基于边界框表述的目标检测器受益，这也说明了RepPoints在灵活目标表述上的优势。

##### 无锚框 vs. 基于锚框

我们首先比较了基于中心点方法（RepPoints一种特殊的设置）与流行的基于锚框检测方法在初始目标假设空间表征上的差别。我们还比较了基于RepPoints的无锚框检测器与RetinaNet、使用RoIAlign的FPN、及采用无锚方式的YOLO网络。我们提出的方法在性能上由于RetinaNet和FPN方法，二者在每个尺度上使用了多个锚框或采用了成熟的锚框配置（FPN）。本方法也远由于YOLO-like方法，这可能是因为RepPoints表述上的灵活以及它有效的精炼。

#### RepPoints可视化

通过可视化，我们可以观察到RepPoints往往在目标极值点或具有丰富语义的点上。这些分布在目标上的点是自主学习得到的，没有明确的监督。同时可视化结果表明本文提出的min-max转换函数能够帮助RPDet有效地检测出小目标。

### 结论

本文提出了RepPoints，一种对位置信息进行精细建模，并识别目标分类局部显著区域的目标检测表征方法。基于RepPoints，我们开发了一个名为RPDet的检测网络，它可以在不使用锚框的情况下达到有竞争力的结果。学习更丰富、更自然的目标表述（如RepPoints)将是一个很有前景的目标检测方向。

## 总结

论文的主要贡献如下：

- 提出了一种新的目标表述方法RepPoints，将其与边界框进行比较，验证了新的目标表征的有效性。
- 在可变卷积上进行改进，实现RepPoints自主学习重新排列样本点，效果显著。

本文基于可变卷积进行优化，提出了一种新的框架，实现对于目标空间特征的表述，个人觉得类似于将目标矩形框打散成点，变得更加灵活，对于特征的提取精细度更高，提升也是正常的。

